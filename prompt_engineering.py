import openai
import logging
import csv
from datetime import datetime
import sqlite3

# Configure logging to store prompt logs
logging.basicConfig(
    filename='prompt_logs.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# OpenAI API key configuration
openai.api_key = "your_openai_api_key_here"

def test_prompt(prompt, model_response):
    """
    Logs the prompt and the model's response for analysis.

    Args:
        prompt (str): The input prompt provided to the AI model.
        model_response (str): The response generated by the AI model.
    """
    logging.info("Prompt: %s", prompt)
    logging.info("Response: %s", model_response)

def generate_prompt(context, question, template="Context: {context}\nQuestion: {question}\nAnswer:"):
    """
    Generates a structured prompt based on the given context, question, and template.

    Args:
        context (str): The context or background information for the prompt.
        question (str): The specific question to ask the AI model.
        template (str): A custom template for the prompt.

    Returns:
        str: A structured prompt.
    """
    return template.format(context=context, question=question)

def get_model_response(prompt):
    """
    Sends the prompt to the OpenAI API and retrieves the model's response.

    Args:
        prompt (str): The input prompt to send to the AI model.

    Returns:
        str: The response from the AI model.
    """
    try:
        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=prompt,
            max_tokens=150
        )
        return response.choices[0].text.strip()
    except Exception as e:
        logging.error("Error while fetching model response: %s", e)
        return "An error occurred while fetching the response."

def batch_test_prompts(csv_file_path):
    """
    Reads prompts and contexts from a CSV file, generates responses, and logs the results.

    Args:
        csv_file_path (str): Path to the CSV file containing 'context' and 'question' columns.
    """
    try:
        with open(csv_file_path, mode='r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                context = row.get('context', '').strip()
                question = row.get('question', '').strip()

                if not context or not question:
                    logging.warning("Skipping row with missing context or question: %s", row)
                    continue

                prompt = generate_prompt(context, question)
                model_response = get_model_response(prompt)

                # Log the prompt and response
                test_prompt(prompt, model_response)

                print(f"Processed Prompt: {prompt}")
                print(f"Model Response: {model_response}\n")
    except FileNotFoundError:
        logging.error("CSV file not found: %s", csv_file_path)
    except Exception as e:
        logging.error("An error occurred during batch testing: %s", e)

def predictive_analytics():
    """
    Predict delays, fuel consumption, or maintenance needs based on historical data.
    """
    try:
        conn = sqlite3.connect('instance/vessel_operations.db')
        cursor = conn.cursor()

        # Example query: Predict delays based on historical data
        cursor.execute("SELECT AVG(delay_hours) FROM operations WHERE weather = 'bad'")
        avg_delay = cursor.fetchone()[0]

        print(f"Predicted average delay during bad weather: {avg_delay} hours")

        # Example query: Predict fuel consumption
        cursor.execute("SELECT AVG(fuel_consumption) FROM voyages")
        avg_fuel = cursor.fetchone()[0]

        print(f"Predicted average fuel consumption: {avg_fuel} liters")

        conn.close()
    except sqlite3.Error as e:
        logging.error("Database error: %s", e)
    except Exception as e:
        logging.error("An error occurred in predictive analytics: %s", e)

if __name__ == "__main__":
    # Example usage
    context = "You are an AI assistant specialized in logistics."
    question = "What are the key challenges in vessel operations?"
    template = "Context: {context}\nQuestion: {question}\nAnswer:"

    prompt = generate_prompt(context, question, template)
    print("Generated Prompt:", prompt)

    # Fetch model response
    model_response = get_model_response(prompt)
    print("Model Response:", model_response)

    # Log the prompt and response
    test_prompt(prompt, model_response)

    # Example usage for batch testing
    csv_file_path = "prompts.csv"  # Replace with the actual path to your CSV file
    batch_test_prompts(csv_file_path)

    # Predictive analytics
    predictive_analytics()